#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§„åˆ™å­¦ä¹ å™¨ - ä»è®­ç»ƒæ•°æ®ä¸­è‡ªåŠ¨æå–APIè¿ç§»è§„åˆ™
"""

import ast
import json
import re
from pathlib import Path
from typing import List, Dict, Tuple, Any
from collections import defaultdict
from difflib import SequenceMatcher
from rich.console import Console
from rich.progress import track

console = Console()


class RuleLearner:
    """ä»æ•°æ®ä¸­å­¦ä¹ APIè¿ç§»è§„åˆ™"""
    
    def __init__(self):
        self.rules = []
        self.api_replacements = defaultdict(int)
        self.parameter_changes = defaultdict(int)
        self.syntax_patterns = []
    
    def learn_from_data(self, training_data: List[Dict]) -> List[Dict]:
        """
        ä»è®­ç»ƒæ•°æ®å­¦ä¹ è§„åˆ™
        
        Args:
            training_data: [(old_code, new_code, description), ...]
            
        Returns:
            å­¦åˆ°çš„è§„åˆ™åˆ—è¡¨
        """
        console.print("\n[cyan]ğŸ“ å¼€å§‹å­¦ä¹ APIè¿ç§»è§„åˆ™...[/cyan]")
        
        for example in track(training_data, description="è§„åˆ™å­¦ä¹ "):
            old_code = example.get("old_code", "")
            new_code = example.get("new_code", "")
            description = example.get("description", "")
            dependency = example.get("dependency", "")
            
            try:
                # 1. æå–APIæ›¿æ¢è§„åˆ™
                api_rules = self._extract_api_replacement_rules(
                    old_code, new_code, dependency
                )
                for rule in api_rules:
                    self.rules.append(rule)
                
                # 2. æå–å‚æ•°è¿ç§»è§„åˆ™
                param_rules = self._extract_parameter_rules(
                    old_code, new_code, dependency
                )
                for rule in param_rules:
                    self.rules.append(rule)
                
                # 3. æå–è¯­æ³•æ¨¡å¼è§„åˆ™
                syntax_rule = self._extract_syntax_pattern(
                    old_code, new_code, description
                )
                if syntax_rule:
                    self.rules.append(syntax_rule)
                    
            except Exception as e:
                console.print(f"[yellow]âš  è§„åˆ™æå–å¤±è´¥: {e}[/yellow]")
                continue
        
        # 4. è§„åˆ™å»é‡ä¸æ³›åŒ–
        self.rules = self._deduplicate_rules(self.rules)
        
        console.print(f"\n[green]âœ“ å­¦åˆ° {len(self.rules)} æ¡è§„åˆ™[/green]")
        self._print_rule_summary()
        
        return self.rules
    
    def _extract_api_replacement_rules(
        self, old_code: str, new_code: str, dependency: str
    ) -> List[Dict]:
        """æå–APIæ›¿æ¢è§„åˆ™ï¼ˆåŸºäºä»£ç å¯¹æ¯”ï¼‰"""
        rules = []
        
        try:
            # æå–APIè°ƒç”¨
            old_funcs = self._extract_function_calls(old_code)
            new_funcs = self._extract_function_calls(new_code)
            
            # ç­–ç•¥1ï¼šç›´æ¥æ›¿æ¢ï¼ˆå®Œæ•´APIè·¯å¾„åŒ¹é…ï¼‰
            for old_api in old_funcs:
                if old_api in old_code and old_api not in new_code:
                    # å¯»æ‰¾æ–°ä»£ç ä¸­å¯¹åº”çš„æ›¿æ¢
                    for new_api in new_funcs:
                        if new_api in new_code and new_api not in old_code:
                            # æ„å»ºè½¬æ¢æ¨¡æ¿
                            rule = self._build_transformation_rule(
                                old_code, new_code, old_api, new_api, dependency
                            )
                            if rule:
                                rules.append(rule)
                                self.api_replacements[(old_api, new_api)] += 1
                                break
            
            # ç­–ç•¥2ï¼šå¦‚æœæ²¡æ‰¾åˆ°ç›´æ¥æ›¿æ¢ï¼Œå°è¯•è¯†åˆ«ç»“æ„æ€§å˜åŒ–
            if not rules:
                structural_rule = self._extract_structural_change(
                    old_code, new_code, dependency
                )
                if structural_rule:
                    rules.append(structural_rule)
        except Exception as e:
            console.print(f"[yellow]APIè§„åˆ™æå–å¤±è´¥: {e}[/yellow]")
        
        return rules
    
    def _build_transformation_rule(
        self, old_code: str, new_code: str, old_api: str, new_api: str, dependency: str
    ) -> Dict:
        """æ„å»ºè½¬æ¢è§„åˆ™ï¼ˆæ”¯æŒå¤æ‚æ¨¡å¼å’Œå‚æ•°æ˜ å°„ï¼‰"""
        # åˆ†æè½¬æ¢ç±»å‹
        transform_type = self._analyze_transform_type(old_code, new_code, old_api, new_api)
        
        # æå–å‚æ•°æ˜ å°„ï¼ˆç”¨äºæ¨¡æ¿åº”ç”¨ï¼‰
        param_mapping = self._extract_parameter_mapping(old_code, new_code, old_api, new_api)
        
        rule = {
            "type": "api_replacement",
            "dependency": dependency,
            "old_api": old_api,
            "new_api": new_api,
            "transform_type": transform_type,
            "old_code_template": old_code,
            "new_code_template": new_code,
            "param_mapping": param_mapping,  # æ–°å¢ï¼šå‚æ•°æ˜ å°„
            "confidence": 0.9,
            "examples": [(old_code, new_code)]
        }
        
        return rule
    
    def _extract_parameter_mapping(self, old_code: str, new_code: str, old_api: str, new_api: str) -> Dict:
        """æå–å‚æ•°æ˜ å°„å…³ç³»"""
        mapping = {}
        
        try:
            # æå–æ—§ä»£ç ä¸­çš„å‚æ•°
            old_args_match = re.search(rf'{re.escape(old_api)}\((.*?)\)', old_code)
            if old_args_match:
                old_args = old_args_match.group(1).strip()
                
                # æå–æ–°ä»£ç ä¸­çš„å‚æ•°
                new_args_match = re.search(rf'{re.escape(new_api)}\((.*?)\)', new_code)
                if new_args_match:
                    new_args = new_args_match.group(1).strip()
                    
                    # ç‰¹æ®Šå¤„ç†ï¼šdf.append(row) â†’ pd.concat([df, row])
                    if 'append' in old_api and 'concat' in new_api:
                        # æå–å¯¹è±¡åï¼ˆdfï¼‰
                        obj_match = re.search(r'(\w+)\.append', old_code)
                        if obj_match:
                            obj_name = obj_match.group(1)
                            mapping['obj'] = obj_name
                            mapping['args'] = old_args
                            mapping['pattern'] = 'append_to_concat'
                    
                    # é€šç”¨æ˜ å°„
                    mapping['old_args'] = old_args
                    mapping['new_args'] = new_args
        except:
            pass
        
        return mapping
    
    def _analyze_transform_type(self, old_code: str, new_code: str, old_api: str, new_api: str) -> str:
        """åˆ†æè½¬æ¢ç±»å‹"""
        # æ£€æµ‹ç‰¹æ®Šæ¨¡å¼
        if 'fit_transform' in old_api and 'fit' in new_api:
            return 'method_chain_split'  # fit_transform â†’ fit().transform()
        
        if old_api.count('.') > new_api.count('.'):
            return 'path_simplification'  # tf.contrib.xxx â†’ tf.keras.xxx
        
        if old_api.count('.') < new_api.count('.'):
            return 'path_expansion'
        
        if '(' in new_code and new_code.count('(') > old_code.count('('):
            return 'call_wrapping'  # flatten(x) â†’ Flatten()(x)
        
        return 'direct_replacement'
    
    def _extract_structural_change(
        self, old_code: str, new_code: str, dependency: str
    ) -> Dict:
        """æå–ç»“æ„æ€§å˜åŒ–è§„åˆ™"""
        # è¯†åˆ«å‚æ•°åå˜åŒ–
        old_params = set(re.findall(r'(\w+)\s*=\s*', old_code))
        new_params = set(re.findall(r'(\w+)\s*=\s*', new_code))
        
        if old_params != new_params:
            changed = {
                'removed': list(old_params - new_params),
                'added': list(new_params - old_params)
            }
            
            return {
                "type": "structural_change",
                "dependency": dependency,
                "change_type": "parameter_rename",
                "changes": changed,
                "old_template": old_code,
                "new_template": new_code,
                "confidence": 0.85,
                "examples": [(old_code, new_code)]
            }
        
        return None
    
    def _extract_parameter_rules(
        self, old_code: str, new_code: str, dependency: str
    ) -> List[Dict]:
        """æå–å‚æ•°è¿ç§»è§„åˆ™"""
        rules = []
        
        try:
            # ä½¿ç”¨æ­£åˆ™æå–å‚æ•°
            old_params = set(re.findall(r'(\w+)\s*=', old_code))
            new_params = set(re.findall(r'(\w+)\s*=', new_code))
            
            # æ‰¾åˆ°æ¶ˆå¤±çš„å‚æ•°
            removed_params = old_params - new_params
            # æ‰¾åˆ°æ–°å¢çš„å‚æ•°
            added_params = new_params - old_params
            
            if removed_params or added_params:
                rule = {
                    "type": "parameter_migration",
                    "dependency": dependency,
                    "removed_params": list(removed_params),
                    "added_params": list(added_params),
                    "confidence": 0.8,
                    "examples": [(old_code, new_code)]
                }
                rules.append(rule)
        except:
            pass
        
        return rules
    
    def _extract_syntax_pattern(
        self, old_code: str, new_code: str, description: str
    ) -> Dict:
        """æå–è¯­æ³•æ¨¡å¼è§„åˆ™"""
        try:
            # å½’ä¸€åŒ–ä»£ç ï¼ˆå»é™¤ç©ºæ ¼ã€å˜é‡åï¼‰
            old_normalized = self._normalize_code(old_code)
            new_normalized = self._normalize_code(new_code)
            
            if old_normalized != new_normalized:
                # æ£€æµ‹ç»“æ„æ€§å˜åŒ–
                structure_type = self._detect_structure_change(
                    old_code, new_code
                )
                
                rule = {
                    "type": "syntax_pattern",
                    "old_pattern": old_normalized,
                    "new_pattern": new_normalized,
                    "structure_type": structure_type,
                    "description": description,
                    "confidence": 0.75,
                    "examples": [(old_code, new_code)]
                }
                return rule
        except:
            pass
        
        return None
    
    def _extract_function_calls(self, code: str) -> List[str]:
        """æå–å‡½æ•°è°ƒç”¨ï¼ˆä¼˜å…ˆæå–å®Œæ•´è·¯å¾„ï¼‰"""
        funcs = []
        
        # æ–¹æ³•1ï¼šæå–å®Œæ•´APIè·¯å¾„ï¼ˆå¦‚ tf.contrib.layers.flatten, pd.concatï¼‰
        full_api_pattern = r'([a-zA-Z_][\w\.]+)\s*\('
        full_matches = re.findall(full_api_pattern, code)
        
        # è¿‡æ»¤ï¼šåªä¿ç•™åŒ…å«ç‚¹å·çš„å®Œæ•´è·¯å¾„ï¼Œæˆ–numpy/pandas/tfç­‰åº“çš„è°ƒç”¨
        for match in full_matches:
            if '.' in match:  # å®Œæ•´è·¯å¾„
                funcs.append(match)
        
        # æ–¹æ³•2ï¼šASTæå–ï¼ˆç”¨äºè·å–æ›´å‡†ç¡®çš„è°ƒç”¨ä¿¡æ¯ï¼‰
        try:
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, ast.Call):
                    # æå–å®Œæ•´è°ƒç”¨è·¯å¾„
                    call_path = self._get_call_path(node.func)
                    if call_path:
                        funcs.append(call_path)
        except:
            pass
        
        return list(set(funcs))
    
    def _get_call_path(self, node) -> str:
        """ä»ASTèŠ‚ç‚¹æå–å®Œæ•´è°ƒç”¨è·¯å¾„"""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            parent = self._get_call_path(node.value)
            if parent:
                return f"{parent}.{node.attr}"
            return node.attr
        return ""
    
    def _normalize_code(self, code: str) -> str:
        """å½’ä¸€åŒ–ä»£ç ï¼ˆç”¨äºæ¨¡å¼åŒ¹é…ï¼‰"""
        # å»é™¤ç©ºæ ¼
        code = re.sub(r'\s+', ' ', code).strip()
        # æ›¿æ¢å˜é‡åä¸ºå ä½ç¬¦
        code = re.sub(r'\b[a-z_]\w*\b', 'VAR', code)
        return code
    
    def _detect_structure_change(self, old_code: str, new_code: str) -> str:
        """æ£€æµ‹ç»“æ„æ€§å˜åŒ–ç±»å‹"""
        # æ£€æµ‹æ˜¯å¦æœ‰èµ‹å€¼åŒ…è£…
        if '=' in new_code and '=' not in old_code:
            return "assignment_wrapping"
        
        # æ£€æµ‹æ˜¯å¦æœ‰åˆ—è¡¨åŒ…è£…
        if '[' in new_code and '[' not in old_code:
            return "list_wrapping"
        
        # æ£€æµ‹æ˜¯å¦æœ‰å‡½æ•°åµŒå¥—
        if new_code.count('(') > old_code.count('('):
            return "function_nesting"
        
        return "unknown"
    
    def _deduplicate_rules(self, rules: List[Dict]) -> List[Dict]:
        """è§„åˆ™å»é‡ä¸åˆå¹¶"""
        unique_rules = {}
        
        for rule in rules:
            rule_type = rule['type']
            
            if rule_type == 'api_replacement':
                key = (rule['old_api'], rule['new_api'])
                if key in unique_rules:
                    # åˆå¹¶ç¤ºä¾‹
                    unique_rules[key]['examples'].extend(rule['examples'])
                    # æ›´æ–°ç½®ä¿¡åº¦
                    unique_rules[key]['confidence'] = min(
                        1.0, unique_rules[key]['confidence'] + 0.05
                    )
                else:
                    unique_rules[key] = rule
            
            elif rule_type == 'parameter_migration':
                key = (
                    rule['dependency'],
                    tuple(sorted(rule['removed_params'])),
                    tuple(sorted(rule['added_params']))
                )
                if key in unique_rules:
                    unique_rules[key]['examples'].extend(rule['examples'])
                    unique_rules[key]['confidence'] = min(
                        1.0, unique_rules[key]['confidence'] + 0.05
                    )
                else:
                    unique_rules[key] = rule
            
            elif rule_type == 'syntax_pattern':
                key = (rule['old_pattern'], rule['new_pattern'])
                if key in unique_rules:
                    unique_rules[key]['examples'].extend(rule['examples'])
                    unique_rules[key]['confidence'] = min(
                        1.0, unique_rules[key]['confidence'] + 0.05
                    )
                else:
                    unique_rules[key] = rule
        
        return list(unique_rules.values())
    
    def _print_rule_summary(self):
        """æ‰“å°è§„åˆ™æ‘˜è¦"""
        from rich.table import Table
        
        table = Table(title="å­¦åˆ°çš„è§„åˆ™ç»Ÿè®¡")
        table.add_column("è§„åˆ™ç±»å‹", style="cyan")
        table.add_column("æ•°é‡", style="green")
        table.add_column("ç¤ºä¾‹", style="yellow")
        
        # ç»Ÿè®¡å„ç±»è§„åˆ™
        rule_counts = defaultdict(int)
        rule_examples = defaultdict(list)
        
        for rule in self.rules:
            rule_type = rule['type']
            rule_counts[rule_type] += 1
            
            if rule_type == 'api_replacement':
                example = f"{rule['old_api']} â†’ {rule['new_api']}"
            elif rule_type == 'parameter_migration':
                example = f"ç§»é™¤: {rule['removed_params']}, æ–°å¢: {rule['added_params']}"
            elif rule_type == 'syntax_pattern':
                example = rule['structure_type']
            else:
                example = "N/A"
            
            if example not in rule_examples[rule_type]:
                rule_examples[rule_type].append(example)
        
        for rule_type, count in rule_counts.items():
            examples = rule_examples[rule_type][:2]  # åªæ˜¾ç¤ºå‰2ä¸ª
            table.add_row(
                rule_type,
                str(count),
                "; ".join(examples)
            )
        
        console.print(table)
    
    def save_rules(self, output_file: str = "../configs/learned_rules.json"):
        """ä¿å­˜è§„åˆ™åº“"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®ï¼ˆå»é™¤examplesä»¥å‡å°æ–‡ä»¶å¤§å°ï¼‰
        rules_to_save = []
        for rule in self.rules:
            rule_copy = rule.copy()
            # åªä¿ç•™examplesçš„æ•°é‡
            rule_copy['example_count'] = len(rule.get('examples', []))
            rule_copy.pop('examples', None)
            rules_to_save.append(rule_copy)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(rules_to_save, f, indent=2, ensure_ascii=False)
        
        console.print(f"\n[green]âœ“ è§„åˆ™åº“å·²ä¿å­˜åˆ°: {output_path}[/green]")
        
        return output_path
    
    @staticmethod
    def load_rules(rule_file: str) -> List[Dict]:
        """åŠ è½½è§„åˆ™åº“"""
        with open(rule_file, 'r', encoding='utf-8') as f:
            rules = json.load(f)
        
        console.print(f"[green]âœ“ åŠ è½½äº† {len(rules)} æ¡è§„åˆ™[/green]")
        return rules


def main():
    """æµ‹è¯•è§„åˆ™å­¦ä¹ å™¨"""
    from data_utils import DataLoader
    
    console.print("[bold cyan]è§„åˆ™å­¦ä¹ å™¨æµ‹è¯•[/bold cyan]\n")
    
    # 1. åŠ è½½è®­ç»ƒæ•°æ®
    data_loader = DataLoader("mini_dataset.json")
    train_data = data_loader.get_train_data()
    console.print(f"âœ“ åŠ è½½äº† {len(train_data)} ä¸ªè®­ç»ƒæ ·æœ¬\n")
    
    # 2. å­¦ä¹ è§„åˆ™
    learner = RuleLearner()
    rules = learner.learn_from_data(train_data)
    
    # 3. ä¿å­˜è§„åˆ™
    learner.save_rules()
    
    # 4. æµ‹è¯•åŠ è½½
    console.print("\n[yellow]æµ‹è¯•è§„åˆ™åŠ è½½...[/yellow]")
    loaded_rules = RuleLearner.load_rules("../configs/learned_rules.json")
    console.print(f"[green]âœ“ æˆåŠŸåŠ è½½ {len(loaded_rules)} æ¡è§„åˆ™[/green]")


if __name__ == "__main__":
    main()
