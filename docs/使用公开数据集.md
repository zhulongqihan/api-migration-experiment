# 使用公开数据集运行混合系统

## 快速开始

### 步骤1：生成公开数据集

```bash
cd ~/api_migration_exp/scripts

# 生成基于真实迁移模式的公开数据集
python3 fetch_public_dataset.py
```

**生成的数据集**：
- **文件名**: `public_dataset.json`
- **训练集**: ~50样本（75%）
- **测试集**: ~15样本（25%）
- **数据来源**: TensorFlow/Pandas/Scikit-learn/NumPy/PyTorch官方文档
- **质量**: （真实官方迁移案例）

---

### 步骤2：运行混合系统

```bash
# 使用公开数据集运行
python3 run_hybrid_system_fixed.py public_dataset.json
```

---

## 数据集详情

### 包含的迁移模式

#### 1. **TensorFlow (14个样本)**
- `tf.contrib.layers.flatten(x)` → `tf.keras.layers.Flatten()(x)`
- `tf.Session()` → `# TF 2.x默认eager模式`
- `tf.placeholder()` → `tf.keras.Input()`
- `tf.train.AdamOptimizer()` → `tf.keras.optimizers.Adam()`

#### 2. **Pandas (16个样本)**
- `df.append(row)` → `pd.concat([df, row])`
- `df.ix[0]` → `df.loc[0]`
- `df.sort('col')` → `df.sort_values('col')`
- `pd.rolling_mean()` → `data.rolling().mean()`

#### 3. **Scikit-learn (7个样本)**
- `from sklearn.cross_validation` → `from sklearn.model_selection`
- `scaler.fit_transform(X)` → `scaler.fit(X).transform(X)`

#### 4. **NumPy (7个样本)**
- `np.matrix()` → `np.array()`
- `arr.tostring()` → `arr.tobytes()`
- `np.rank()` → `np.ndim()`

#### 5. **PyTorch (9个样本)**
- `torch.save(model)` → `torch.save(model.state_dict())`
- `model.cuda()` → `model.to('cuda')`
- `Variable(tensor)` → `tensor`

---

## 数据集质量对比

| 数据集 | 样本数 | 真实性 | 多样性 | 推荐度 |
|--------|--------|--------|--------|--------|
| mini_dataset.json | 40 | | | 太小 |
| large_dataset.json | 130 | | | 好 |
| public_dataset.json | 60+ | | | 最佳 |

---

## 预期性能

使用公开数据集，预期指标：

```
精确匹配率: 50-70%
平均相似度: 0.65-0.80
关键API准确率: 70-85%
规则直接应用准确率: 85-95%
```

---

## 进阶：扩展数据集

### 方法1：增加更多库

编辑 `fetch_public_dataset.py`，添加：
- Matplotlib迁移
- Requests迁移
- PIL/Pillow迁移
- Django迁移

### 方法2：从GitHub获取真实项目数据

```bash
# 克隆包含真实迁移的项目
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git log --all --grep="migrate" --oneline

# 提取迁移commit的diff
git show <commit_hash>
```

### 方法3：使用APIMigrationBench

```bash
# 下载APIMigrationBench（如果可用）
git clone https://github.com/NAIST-SE/APIMigrationBench.git
cd APIMigrationBench

# 转换为我们的格式
python3 convert_api_bench.py
```

---

## 故障排除

### 问题1：数据集太小
**解决**: 运行多次`fetch_public_dataset.py`生成更多变体

### 问题2：某些库的迁移样本不足
**解决**: 手动添加到`fetch_public_dataset.py`相应方法中

### 问题3：规则学习效果不好
**解决**: 
- 增加训练样本数量（75% → 80%）
- 检查数据质量（确保old_code和new_code真实对应）

---

## 数据集格式

```json
{
 "train": [
 {
 "id": "tf_1",
 "old_code": "tf.contrib.layers.flatten(x)",
 "new_code": "tf.keras.layers.Flatten()(x)",
 "dependency": "tensorflow",
 "description": "contrib.layers.flatten已移除",
 "source": "TensorFlow Official Guide"
 }
 ],
 "test": [...]
}
```

---

## 验证数据集质量

```bash
# 查看数据集统计
python3 -c "
import json
with open('public_dataset.json') as f:
 data = json.load(f)
 print(f'训练集: {len(data[\"train\"])}')
 print(f'测试集: {len(data[\"test\"])}')
 
 # 统计每个库的样本数
 libs = {}
 for sample in data['train']:
 lib = sample['dependency']
 libs[lib] = libs.get(lib, 0) + 1
 
 for lib, count in sorted(libs.items()):
 print(f'{lib}: {count}')
"
```
