# 紧急修复指南

## 问题诊断

从运行输出看到3个严重问题：

### 问题1：训练数据太少 
```
训练集: 3 个样本 （应该是40个）
```

### 问题2：LLM生成失败 
```
生成: !!!!!!!!!!!!!!!!!!!!!!!!...
```

### 问题3：规则应用错误 
```
旧代码: new_df = old_df.append(row)
生成: new_df = old_df.pd.concat(row) 
期望: new_df = pd.concat()
```

---

## 快速修复方案

### 方案A：使用修复版脚本（推荐）

已创建修复版脚本，包含所有问题的修复。

#### Step 1: 上传修复文件

上传以下修复后的文件到服务器 `~/api_migration_exp/scripts/`:

```
 hybrid_generator.py（已修复LLM生成）
 rule_matcher.py（已修复规则应用）
 run_hybrid_fixed.py（新建：修复版运行脚本）
```

#### Step 2: 运行修复版

```bash
cd ~/api_migration_exp/scripts

# 使用扩展数据集（40个训练样本）
python3 run_hybrid_fixed.py --data_file extended_dataset_50.json

# 或者先测试前5个样本
python3 run_hybrid_fixed.py --data_file extended_dataset_50.json --test_only 5
```

**预计改进**：
- 精确匹配率：0% → 80-90%
- 规则覆盖率：30% → 60-70%
- LLM生成质量：大幅提升

---

### 方案B：手动修复（如果方案A失败）

#### 修复1：使用正确的数据集

```bash
# 检查数据集
cd ~/api_migration_exp/scripts
python3 -c "from data_utils import DataLoader; d=DataLoader('extended_dataset_50.json'); print(f'训练:{len(d.get_train_data())}, 测试:{len(d.get_test_data())}')"

# 应该显示：训练:40, 测试:10
```

如果`extended_dataset_50.json`不存在：

```bash
# 从原始数据生成
# （需要你提供转换脚本或手动准备数据）
```

#### 修复2：检查LLM是否正常

```bash
# 测试LLM生成
python3 -c "
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-Coder-1.5B', trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-Coder-1.5B', torch_dtype=torch.float16, trust_remote_code=True).cuda()

prompt = 'def hello():'
inputs = tokenizer(prompt, return_tensors='pt').to('cuda')
outputs = model.generate(**inputs, max_new_tokens=50, do_sample=False, repetition_penalty=1.1)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
"
```

如果生成正常文本（不是感叹号），说明模型没问题。

#### 修复3：手动修改rule_matcher.py

如果上传失败，手动编辑：

```bash
nano rule_matcher.py

# 找到 _apply_api_rule 函数（约第149行）
# 将简单的 code.replace(old_api, new_api) 
# 改为使用正则表达式的词边界匹配
```

---

## 预期修复效果

### 修复前
```
精确匹配率: 0.0%
平均相似度: 0.073
规则直接应用: 1次 (0%准确)
```

### 修复后（预期）
```
精确匹配率: 80-90%
平均相似度: 0.90-0.95
规则直接应用: 6-7次 (85%+ 准确)
规则引导Prompt: 2-3次 (75%+ 准确)
LLM兜底: 1-2次 (60%+ 准确)
```

---

## 诊断命令

### 检查数据集

```bash
cd ~/api_migration_exp/scripts

# 检查mini_dataset.json
python3 data_utils.py mini_dataset.json

# 检查extended_dataset_50.json 
python3 data_utils.py extended_dataset_50.json
```

### 检查规则库

```bash
# 查看学到的规则
cat ../configs/learned_rules.json | python3 -m json.tool | head -50
```

### 检查生成结果

```bash
# 查看失败案例
cat ../results/hybrid/hybrid_results_*.json | python3 -m json.tool | grep -A 5 "generated_code"
```

---

## 已知问题

### 问题：数据集格式

**症状**：训练集只有3个样本

**原因**：`mini_dataset.json`是早期测试数据，样本太少

**解决**：使用`extended_dataset_50.json`（40训练 + 10测试）

### 问题：LLM重复生成

**症状**：生成大量感叹号或重复字符

**原因**：
1. 未设置`repetition_penalty`
2. 可能是prompt格式问题

**解决**：
1. 添加`repetition_penalty=1.1`（已修复）
2. 检查prompt是否有特殊字符

### 问题：规则应用错误

**症状**：`old_df.pd.concat(row)`这种错误代码

**原因**：简单字符串替换，部分匹配导致错误

**解决**：
1. 使用正则表达式词边界匹配
2. 针对特定模式（如append→concat）特殊处理

---

## 立即执行

### 选项1：完全重新运行（推荐）

```bash
# 1. 重新上传修复后的文件
# hybrid_generator.py, rule_matcher.py, run_hybrid_fixed.py

# 2. 运行修复版
cd ~/api_migration_exp/scripts
python3 run_hybrid_fixed.py --data_file extended_dataset_50.json --test_only 5

# 3. 如果5个样本测试成功（准确率>70%），运行完整测试
python3 run_hybrid_fixed.py --data_file extended_dataset_50.json
```

### 选项2：快速验证（5分钟）

```bash
# 只测试LLM是否正常
python3 -c "
from hybrid_generator import HybridGenerator
from rule_matcher import RuleMatcher

matcher = RuleMatcher([], confidence_threshold=0.9)
gen = HybridGenerator(matcher, device='cuda')

code = 'df.append(row)'
new_code, strategy, conf = gen.generate(code, 'Update append to concat')
print(f'生成: {new_code}')
print(f'策略: {strategy}')
"
```

---

## 成功标准

修复成功的判断标准：

- [ ] 训练集 ≥ 30个样本
- [ ] LLM不生成感叹号
- [ ] 精确匹配率 ≥ 75%
- [ ] 规则覆盖率 ≥ 50%

---

**立即上传修复文件并重新运行！** 
